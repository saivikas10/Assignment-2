{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import json\n",
        "import string\n",
        "import pickle\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Hw2dO9BGajlR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Given Code with Forward() Filled**"
      ],
      "metadata": {
        "id": "uz8HdbCeHSbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GitHub file URLs for data download\n",
        "train_data_url = \"https://raw.githubusercontent.com/saivikas10/Assignment-2/refs/heads/main/training.json\"\n",
        "validation_data_url = \"https://raw.githubusercontent.com/saivikas10/Assignment-2/refs/heads/main/validation.json\"\n",
        "test_data_url = \"https://raw.githubusercontent.com/saivikas10/Assignment-2/refs/heads/main/test.json\"\n"
      ],
      "metadata": {
        "id": "Njrs4ymXap3o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data files from GitHub\n",
        "def download_data(url, filename):\n",
        "    response = requests.get(url)\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(response.text)\n",
        "\n",
        "download_data(train_data_url, 'training.json')\n",
        "download_data(validation_data_url, 'validation.json')\n",
        "download_data(test_data_url, 'test.json')\n",
        "!wget \"https://media.githubusercontent.com/media/saivikas10/Assignment-2/refs/heads/main/word_embedding.pkl\" -O \"word_embedding.pkl\"\n",
        "print(\"Data files downloaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLMWatHRas3i",
        "outputId": "f82b65e6-6fb7-45f7-f439-d3075301f3fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-12 17:42:31--  https://media.githubusercontent.com/media/saivikas10/Assignment-2/refs/heads/main/word_embedding.pkl\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 108556651 (104M) [application/octet-stream]\n",
            "Saving to: ‘word_embedding.pkl’\n",
            "\n",
            "word_embedding.pkl  100%[===================>] 103.53M  76.9MB/s    in 1.3s    \n",
            "\n",
            "2024-11-12 17:42:34 (76.9 MB/s) - ‘word_embedding.pkl’ saved [108556651/108556651]\n",
            "\n",
            "Data files downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RNN model class\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_dim, h):  # Add relevant parameters\n",
        "        super(RNN, self).__init__()\n",
        "        self.h = h\n",
        "        self.numOfLayer = 1\n",
        "        self.rnn = nn.RNN(input_dim, h, self.numOfLayer, nonlinearity='tanh', batch_first=True)\n",
        "        self.W = nn.Linear(h, 5)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        self.loss = nn.NLLLoss()\n",
        "\n",
        "  def compute_Loss(self, predicted_vector, gold_label):\n",
        "        return self.loss(predicted_vector, gold_label)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "        # Obtain hidden layer representation\n",
        "        _, hidden = self.rnn(inputs)\n",
        "        # Obtain output layer representations\n",
        "        out = self.W(hidden[:, -1, :])\n",
        "        # Obtain probability distribution\n",
        "        predicted_vector = self.softmax(out)\n",
        "        return predicted_vector"
      ],
      "metadata": {
        "id": "qXcBW8A1YtyR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unk = '<UNK>'\n",
        "\n",
        "\n",
        "def load_data(train_data, val_data):\n",
        "  with open(train_data) as training_f:\n",
        "      training = json.load(training_f)\n",
        "  with open(val_data) as valid_f:\n",
        "      validation = json.load(valid_f)\n",
        "\n",
        "  tra = []\n",
        "  val = []\n",
        "  for elt in training:\n",
        "      tra.append((elt[\"text\"].split(), int(elt[\"stars\"] - 1)))\n",
        "  for elt in validation:\n",
        "      val.append((elt[\"text\"].split(), int(elt[\"stars\"] - 1)))\n",
        "  return tra, val\n",
        "\n",
        "# Load word embeddings\n",
        "def load_embeddings(filepath):\n",
        "    with open(filepath, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Load data\n",
        "print(\"========== Loading data ==========\")\n",
        "training_path = 'training.json'\n",
        "validation_path = 'validation.json'\n",
        "training_data, validation_data = load_data(training_path,  validation_path)  # Load data\n",
        "print(\"Data loaded successfully.\")\n",
        "\n",
        "# Prepare word embeddings\n",
        "print(\"========== Vectorizing data ==========\")\n",
        "word_embedding = load_embeddings('word_embedding.pkl')  # Make sure to upload this file\n",
        "\n",
        "# Set default configurations for Colab\n",
        "hidden_dim = 10\n",
        "epochs = 5\n",
        "minibatch_size = 16\n",
        "\n",
        "print(\"==========Running for Default Configuration==========\")\n",
        "print(\"Hidden_dim =\", hidden_dim)\n",
        "print(\"Epochs =\", epochs)\n",
        "print(\"Learning Rate =\", 0.01)\n",
        "print(\"Batch Size =\", minibatch_size)\n",
        "\n",
        "model = RNN(50, hidden_dim)  # Initialize model\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "stopping_condition = False\n",
        "epoch = 0\n",
        "last_train_accuracy = 0\n",
        "last_validation_accuracy = 0\n",
        "\n",
        "while not stopping_condition:\n",
        "    random.shuffle(training_data)\n",
        "    model.train()\n",
        "    print(\"Training started for epoch {}\".format(epoch + 1))\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    N = len(training_data)\n",
        "\n",
        "    loss_total = 0\n",
        "    loss_count = 0\n",
        "    for minibatch_index in tqdm(range(N // minibatch_size)):\n",
        "        optimizer.zero_grad()\n",
        "        loss = None\n",
        "        for example_index in range(minibatch_size):\n",
        "            input_words, gold_label = training_data[minibatch_index * minibatch_size + example_index]\n",
        "            input_words = \" \".join(input_words)\n",
        "\n",
        "            # Remove punctuation\n",
        "            input_words = input_words.translate(input_words.maketrans(\"\", \"\", string.punctuation)).split()\n",
        "\n",
        "            # Look up word embedding dictionary\n",
        "            vectors = [word_embedding.get(i.lower(), np.zeros(next(iter(word_embedding.values())).shape)) for i in input_words]\n",
        "\n",
        "            # Transform the input into required shape and convert to float32\n",
        "            vectors = torch.tensor(vectors, dtype=torch.float32).view(len(vectors), 1, -1)  # Shape to (seq_len, 1, embedding_dim)\n",
        "            output = model(vectors)\n",
        "\n",
        "            # Get loss\n",
        "            example_loss = model.compute_Loss(output.view(1, -1), torch.tensor([gold_label]))\n",
        "\n",
        "            # Get predicted label\n",
        "            predicted_label = torch.argmax(output)\n",
        "\n",
        "            correct += int(predicted_label == gold_label)\n",
        "            total += 1\n",
        "            if loss is None:\n",
        "                loss = example_loss\n",
        "            else:\n",
        "                loss += example_loss\n",
        "\n",
        "        loss = loss / minibatch_size\n",
        "        loss_total += loss.data\n",
        "        loss_count += 1\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = loss_total / loss_count\n",
        "    print(\"Training completed for epoch {}\".format(epoch + 1))\n",
        "    print(\"Training accuracy for epoch {}: {}\".format(epoch + 1, correct / total))\n",
        "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
        "    training_accuracy = correct / total\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    random.shuffle(validation_data)\n",
        "    print(\"Validation started for epoch {}\".format(epoch + 1))\n",
        "\n",
        "    for input_words, gold_label in tqdm(validation_data):\n",
        "        input_words = \" \".join(input_words)\n",
        "        input_words = input_words.translate(input_words.maketrans(\"\", \"\", string.punctuation)).split()\n",
        "        vectors = [word_embedding.get(i.lower(), np.zeros(next(iter(word_embedding.values())).shape)) for i in input_words]\n",
        "\n",
        "        vectors = torch.tensor(vectors, dtype=torch.float32).view(len(vectors), 1, -1)  # Ensure the correct shape\n",
        "        output = model(vectors)\n",
        "        predicted_label = torch.argmax(output)\n",
        "        correct += int(predicted_label == gold_label)\n",
        "        total += 1\n",
        "\n",
        "    print(\"Validation completed for epoch {}\".format(epoch + 1))\n",
        "    print(\"Validation accuracy for epoch {}: {}\".format(epoch + 1, correct / total))\n",
        "    validation_accuracy = correct / total\n",
        "\n",
        "    if validation_accuracy < last_validation_accuracy and training_accuracy > last_train_accuracy:\n",
        "        stopping_condition = True\n",
        "        print(\"Training done to avoid overfitting!\")\n",
        "        print(\"Best validation accuracy is:\", last_validation_accuracy)\n",
        "    else:\n",
        "        last_validation_accuracy = validation_accuracy\n",
        "        last_train_accuracy = training_accuracy\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "print(\"Final Validation Accuracy:\", last_validation_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Toz1ktXoz4xj",
        "outputId": "486e32d7-3c2b-4f1f-c4ea-95f11e12ecc1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Loading data ==========\n",
            "Data loaded successfully.\n",
            "========== Vectorizing data ==========\n",
            "==========Running for Default Configuration==========\n",
            "Hidden_dim = 10\n",
            "Epochs = 5\n",
            "Learning Rate = 0.01\n",
            "Batch Size = 16\n",
            "Training started for epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]<ipython-input-5-699f77545af5>:77: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  vectors = torch.tensor(vectors, dtype=torch.float32).view(len(vectors), 1, -1)  # Shape to (seq_len, 1, embedding_dim)\n",
            "100%|██████████| 1000/1000 [00:58<00:00, 16.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed for epoch 1\n",
            "Training accuracy for epoch 1: 0.2460625\n",
            "Average Loss: 1.5953\n",
            "Validation started for epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:01<00:00, 437.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation completed for epoch 1\n",
            "Validation accuracy for epoch 1: 0.2575\n",
            "Training started for epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:45<00:00, 22.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed for epoch 2\n",
            "Training accuracy for epoch 2: 0.2580625\n",
            "Average Loss: 1.5813\n",
            "Validation started for epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:02<00:00, 287.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation completed for epoch 2\n",
            "Validation accuracy for epoch 2: 0.3\n",
            "Training started for epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:45<00:00, 21.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed for epoch 3\n",
            "Training accuracy for epoch 3: 0.2643125\n",
            "Average Loss: 1.5747\n",
            "Validation started for epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:01<00:00, 462.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation completed for epoch 3\n",
            "Validation accuracy for epoch 3: 0.2475\n",
            "Training done to avoid overfitting!\n",
            "Best validation accuracy is: 0.3\n",
            "Final Validation Accuracy: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Code to Run Different Configurations and Plot the Best Model**"
      ],
      "metadata": {
        "id": "i8xZ5mYGIrk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set configurations for running the RNN\n",
        "configs = [\n",
        "    {'epochs': 5, 'hidden_dim': 5, 'learning_rate': 0.01, 'batch_size': 16},\n",
        "    {'epochs': 10, 'hidden_dim': 5, 'learning_rate': 0.01, 'batch_size': 16},\n",
        "    {'epochs': 5, 'hidden_dim': 10, 'learning_rate': 0.1, 'batch_size': 32},\n",
        "    {'epochs': 10, 'hidden_dim': 10, 'learning_rate': 0.01, 'batch_size': 32},\n",
        "    {'epochs': 15, 'hidden_dim': 15, 'learning_rate': 0.001, 'batch_size': 64}\n",
        "]\n",
        "\n",
        "best_validation_accuracy = 0\n",
        "best_train_losses, best_train_accuracies, best_validation_accuracies = [], [], []\n",
        "best_configuration = None\n",
        "\n",
        "# Run each configuration\n",
        "for config_num, config in enumerate(configs, start=1):\n",
        "\n",
        "    print(f\"\\nCONFIGURATION {config_num}:\")\n",
        "    hidden_dim = config['hidden_dim']\n",
        "    epochs = config['epochs']\n",
        "    learning_rate = config['learning_rate']\n",
        "    batch_size = config['batch_size']\n",
        "\n",
        "    print(f\"Hidden Dimension: {hidden_dim}, Epochs: {epochs}, Learning Rate: {learning_rate}, Batch Size: {batch_size}\")\n",
        "\n",
        "    # Initializing model and optimizer\n",
        "    model = RNN(50, hidden_dim)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_losses, train_accuracies, val_accuracies = [], [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        total_loss = 0\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}:\")\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        for minibatch_index in tqdm(range(len(training_data) // batch_size), desc=f\"Epoch {epoch + 1} Progress\"):\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss = None\n",
        "            for example_index in range(batch_size):\n",
        "                input_words, gold_label = training_data[minibatch_index * batch_size + example_index]\n",
        "                input_words = \" \".join(input_words).translate(str.maketrans(\"\", \"\", string.punctuation)).split()\n",
        "                vectors = [word_embedding.get(word.lower(), np.zeros(50)) for word in input_words]\n",
        "                vectors = torch.tensor(vectors, dtype=torch.float32).view(len(vectors), 1, -1)\n",
        "                output = model(vectors)\n",
        "                example_loss = model.compute_Loss(output.view(1, -1), torch.tensor([gold_label]))\n",
        "\n",
        "                if batch_loss is None:\n",
        "                    batch_loss = example_loss\n",
        "                else:\n",
        "                    batch_loss += example_loss\n",
        "\n",
        "                predicted_label = torch.argmax(output)\n",
        "                correct_train += int(predicted_label == gold_label)\n",
        "                total_train += 1\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += batch_loss.item()\n",
        "\n",
        "        avgerage_train_loss = total_loss / (len(training_data) // batch_size)\n",
        "        train_accuracy = correct_train / total_train\n",
        "        train_losses.append(avgerage_train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "        with torch.no_grad():\n",
        "            for input_words, gold_label in validation_data:\n",
        "                input_words = \" \".join(input_words).translate(str.maketrans(\"\", \"\", string.punctuation)).split()\n",
        "                vectors = [word_embedding.get(word.lower(), np.zeros(50)) for word in input_words]\n",
        "                vectors = torch.tensor(vectors, dtype=torch.float32).view(len(vectors), 1, -1)\n",
        "                output = model(vectors)\n",
        "                predicted_label = torch.argmax(output)\n",
        "                correct_val += int(predicted_label == gold_label)\n",
        "                total_val += 1\n",
        "\n",
        "        val_accuracy = correct_val / total_val\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        # Print epoch results in Code 2 format\n",
        "        print(f\"Training Loss = {avgerage_train_loss:.4f}, Training Accuracy = {train_accuracy:.4f}, Validation Accuracy = {val_accuracy:.4f}\")\n",
        "    # Print final training and validation accuracy for this configuration\n",
        "    print(f\"\\nFinal Training Accuracy for Config {config_num}: {train_accuracy:.4f}\")\n",
        "    print(f\"Final Validation Accuracy for Config {config_num}: {val_accuracy:.4f}\")\n",
        "    print(\"==============\\n\")\n",
        "\n",
        "    # Checking if this configuration has the best validation accuracy\n",
        "    if val_accuracies[-1] > best_validation_accuracy:\n",
        "        best_validation_accuracy = val_accuracies[-1]\n",
        "        best_train_losses = train_losses\n",
        "        best_train_accuracies = train_accuracies\n",
        "        best_validation_accuracies = val_accuracies\n",
        "        best_configuration = config\n",
        "\n",
        "# Print the best configuration and validation accuracy\n",
        "print(\"\\nBest Configuration:\")\n",
        "print(f\"Hidden Dim: {best_configuration['hidden_dim']}\")\n",
        "print(f\"Epochs: {best_configuration['epochs']}\")\n",
        "print(f\"Learning Rate: {best_configuration['learning_rate']}\")\n",
        "print(f\"Batch Size: {best_configuration['batch_size']}\")\n",
        "print(f\"Best Validation Accuracy: {best_validation_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RprgZ8WO2-_m",
        "outputId": "873335b9-488e-4ca8-c12e-4d8cd05fcea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONFIGURATION 1:\n",
            "Hidden Dimension: 5, Epochs: 5, Learning Rate: 0.01, Batch Size: 16\n",
            "Epoch 1/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Progress: 100%|██████████| 1000/1000 [00:44<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.5340, Training Accuracy = 0.2366, Validation Accuracy = 0.2637\n",
            "Epoch 2/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Progress: 100%|██████████| 1000/1000 [00:49<00:00, 20.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.3288, Training Accuracy = 0.2539, Validation Accuracy = 0.2737\n",
            "Epoch 3/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Progress: 100%|██████████| 1000/1000 [00:46<00:00, 21.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.2601, Training Accuracy = 0.2564, Validation Accuracy = 0.2787\n",
            "Epoch 4/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Progress: 100%|██████████| 1000/1000 [00:48<00:00, 20.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.2190, Training Accuracy = 0.2592, Validation Accuracy = 0.2775\n",
            "Epoch 5/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Progress: 100%|██████████| 1000/1000 [00:46<00:00, 21.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.1821, Training Accuracy = 0.2611, Validation Accuracy = 0.2812\n",
            "\n",
            "Final Training Accuracy for Config 1: 0.2611\n",
            "Final Validation Accuracy for Config 1: 0.2812\n",
            "==============\n",
            "\n",
            "\n",
            "CONFIGURATION 2:\n",
            "Hidden Dimension: 5, Epochs: 10, Learning Rate: 0.01, Batch Size: 16\n",
            "Epoch 1/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Progress: 100%|██████████| 1000/1000 [00:49<00:00, 20.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.6028, Training Accuracy = 0.2320, Validation Accuracy = 0.3300\n",
            "Epoch 2/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Progress: 100%|██████████| 1000/1000 [00:43<00:00, 22.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.3440, Training Accuracy = 0.2542, Validation Accuracy = 0.3438\n",
            "Epoch 3/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Progress: 100%|██████████| 1000/1000 [00:50<00:00, 20.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.2488, Training Accuracy = 0.2609, Validation Accuracy = 0.3312\n",
            "Epoch 4/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Progress: 100%|██████████| 1000/1000 [00:45<00:00, 21.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.1931, Training Accuracy = 0.2672, Validation Accuracy = 0.3137\n",
            "Epoch 5/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Progress: 100%|██████████| 1000/1000 [00:44<00:00, 22.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.1523, Training Accuracy = 0.2686, Validation Accuracy = 0.3225\n",
            "Epoch 6/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Progress: 100%|██████████| 1000/1000 [00:47<00:00, 20.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.1242, Training Accuracy = 0.2722, Validation Accuracy = 0.3162\n",
            "Epoch 7/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Progress: 100%|██████████| 1000/1000 [00:46<00:00, 21.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.1005, Training Accuracy = 0.2709, Validation Accuracy = 0.3287\n",
            "Epoch 8/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Progress: 100%|██████████| 1000/1000 [00:42<00:00, 23.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.0828, Training Accuracy = 0.2704, Validation Accuracy = 0.3237\n",
            "Epoch 9/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Progress: 100%|██████████| 1000/1000 [00:43<00:00, 23.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.0668, Training Accuracy = 0.2722, Validation Accuracy = 0.3150\n",
            "Epoch 10/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Progress: 100%|██████████| 1000/1000 [00:45<00:00, 22.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 25.0518, Training Accuracy = 0.2715, Validation Accuracy = 0.3137\n",
            "\n",
            "Final Training Accuracy for Config 2: 0.2715\n",
            "Final Validation Accuracy for Config 2: 0.3137\n",
            "==============\n",
            "\n",
            "\n",
            "CONFIGURATION 3:\n",
            "Hidden Dimension: 10, Epochs: 5, Learning Rate: 0.1, Batch Size: 32\n",
            "Epoch 1/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Progress: 100%|██████████| 500/500 [00:42<00:00, 11.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 53.4658, Training Accuracy = 0.2188, Validation Accuracy = 0.0925\n",
            "Epoch 2/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Progress: 100%|██████████| 500/500 [00:46<00:00, 10.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 53.3580, Training Accuracy = 0.2277, Validation Accuracy = 0.1200\n",
            "Epoch 3/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Progress: 100%|██████████| 500/500 [00:44<00:00, 11.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 53.1366, Training Accuracy = 0.2267, Validation Accuracy = 0.1212\n",
            "Epoch 4/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Progress: 100%|██████████| 500/500 [00:46<00:00, 10.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 53.2669, Training Accuracy = 0.2328, Validation Accuracy = 0.1500\n",
            "Epoch 5/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Progress: 100%|██████████| 500/500 [00:46<00:00, 10.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 53.0880, Training Accuracy = 0.2351, Validation Accuracy = 0.0988\n",
            "\n",
            "Final Training Accuracy for Config 3: 0.2351\n",
            "Final Validation Accuracy for Config 3: 0.0988\n",
            "==============\n",
            "\n",
            "\n",
            "CONFIGURATION 4:\n",
            "Hidden Dimension: 10, Epochs: 10, Learning Rate: 0.01, Batch Size: 32\n",
            "Epoch 1/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Progress: 100%|██████████| 500/500 [00:52<00:00,  9.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 50.8761, Training Accuracy = 0.2468, Validation Accuracy = 0.3412\n",
            "Epoch 2/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Progress: 100%|██████████| 500/500 [00:46<00:00, 10.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 50.4335, Training Accuracy = 0.2608, Validation Accuracy = 0.3312\n",
            "Epoch 3/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Progress: 100%|██████████| 500/500 [00:48<00:00, 10.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 50.2355, Training Accuracy = 0.2711, Validation Accuracy = 0.3412\n",
            "Epoch 4/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Progress: 100%|██████████| 500/500 [00:44<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 50.0897, Training Accuracy = 0.2764, Validation Accuracy = 0.3237\n",
            "Epoch 5/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Progress: 100%|██████████| 500/500 [00:44<00:00, 11.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 49.9614, Training Accuracy = 0.2799, Validation Accuracy = 0.3137\n",
            "Epoch 6/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Progress: 100%|██████████| 500/500 [00:43<00:00, 11.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 49.8406, Training Accuracy = 0.2833, Validation Accuracy = 0.3175\n",
            "Epoch 7/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Progress: 100%|██████████| 500/500 [00:42<00:00, 11.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 49.7482, Training Accuracy = 0.2851, Validation Accuracy = 0.3150\n",
            "Epoch 8/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Progress: 100%|██████████| 500/500 [00:44<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 49.6803, Training Accuracy = 0.2851, Validation Accuracy = 0.3250\n",
            "Epoch 9/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Progress: 100%|██████████| 500/500 [00:42<00:00, 11.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 49.6264, Training Accuracy = 0.2883, Validation Accuracy = 0.3137\n",
            "Epoch 10/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Progress: 100%|██████████| 500/500 [00:43<00:00, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 49.5740, Training Accuracy = 0.2884, Validation Accuracy = 0.3137\n",
            "\n",
            "Final Training Accuracy for Config 4: 0.2884\n",
            "Final Validation Accuracy for Config 4: 0.3137\n",
            "==============\n",
            "\n",
            "\n",
            "CONFIGURATION 5:\n",
            "Hidden Dimension: 15, Epochs: 15, Learning Rate: 0.001, Batch Size: 64\n",
            "Epoch 1/15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Progress: 100%|██████████| 250/250 [00:43<00:00,  5.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 103.2942, Training Accuracy = 0.2179, Validation Accuracy = 0.2325\n",
            "Epoch 2/15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Progress: 100%|██████████| 250/250 [00:42<00:00,  5.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 101.7441, Training Accuracy = 0.2476, Validation Accuracy = 0.2625\n",
            "Epoch 3/15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Progress: 100%|██████████| 250/250 [00:44<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 101.2007, Training Accuracy = 0.2589, Validation Accuracy = 0.2662\n",
            "Epoch 4/15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Progress: 100%|██████████| 250/250 [00:42<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 100.9039, Training Accuracy = 0.2671, Validation Accuracy = 0.2562\n",
            "Epoch 5/15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Progress: 100%|██████████| 250/250 [00:44<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 100.7026, Training Accuracy = 0.2697, Validation Accuracy = 0.2537\n",
            "Epoch 6/15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Progress: 100%|██████████| 250/250 [00:42<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 100.5454, Training Accuracy = 0.2733, Validation Accuracy = 0.2525\n",
            "Epoch 7/15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Progress: 100%|██████████| 250/250 [00:42<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 100.4116, Training Accuracy = 0.2745, Validation Accuracy = 0.2450\n",
            "Epoch 8/15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Progress: 100%|██████████| 250/250 [00:41<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss = 100.2921, Training Accuracy = 0.2764, Validation Accuracy = 0.2475\n",
            "Epoch 9/15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Progress:   4%|▍         | 10/250 [00:01<00:41,  5.84it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Training Loss, Training Accuracy, and Validation Accuracy for the best model\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "# Training Loss plot\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title('Training Loss vs Epochs (Best Model)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.plot(range(1, len(best_train_losses) + 1), best_train_losses, marker='o')\n",
        "\n",
        "# Training Accuracy plot\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title('Training Accuracy vs Epochs (Best Model)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Accuracy')\n",
        "plt.plot(range(1, len(best_train_accuracies) + 1), best_train_accuracies, marker='o')\n",
        "\n",
        "# Validation Accuracy plot\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title('Validation Accuracy vs Epochs (Best Model)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.plot(range(1, len(best_validation_accuracies) + 1), best_validation_accuracies, marker='o')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UUIakzLuY7R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing the Best Model**"
      ],
      "metadata": {
        "id": "rjqvIgT9IwZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading test data\n",
        "test_data_path = 'test.json'\n",
        "test_data, _ = load_data(test_data_path, test_data_path)\n",
        "\n",
        "# Initializing the best model according on the best configuration\n",
        "BestModel = RNN(50, best_configuration['hidden_dim'])\n",
        "BestModel.eval()  # Setting model to evaluation mode\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "# Calculating test accuracy\n",
        "with torch.no_grad():\n",
        "    for input_words, gold_label in test_data:\n",
        "        # Prepare the input by removing punctuation and converting to embeddings\n",
        "        input_words = \" \".join(input_words).translate(str.maketrans(\"\", \"\", string.punctuation)).split()\n",
        "        vectors = [word_embedding.get(word.lower(), np.zeros(50)) for word in input_words]\n",
        "        vectors = torch.tensor(vectors, dtype=torch.float32).view(len(vectors), 1, -1)\n",
        "\n",
        "        #Getting model output and calculating accuracy\n",
        "        output = BestModel(vectors)\n",
        "        predicted_label = torch.argmax(output)\n",
        "        test_correct += int(predicted_label == gold_label)\n",
        "        test_total += 1\n",
        "\n",
        "# Calculating test accuracy\n",
        "Testing_Accuracy = test_correct / test_total if test_total > 0 else 0\n",
        "print(f\"\\nTest Accuracy for Best Model: {Testing_Accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyoYrlUm9YJA",
        "outputId": "f0d8adb0-aa7d-47f2-a705-38348fe9ff11"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy for Best Model: 0.3738\n"
          ]
        }
      ]
    }
  ]
}